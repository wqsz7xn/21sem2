* Lecture 1
- End goal: achieve speedup of k fold when you have k processors, in the real
  world this doesn't happen but we want to be as close to this as possible, this
  is the upperbound limit
** Elements of a Parallel Computer
 - Hardware
   - Multiple processes
   - Multiple memories
   - Interconnection network (ICN)
 - System Software
   - Parallel operating system
   - Programming constructs to express/orchestrate concurrency
 - Application Software
   - Parallel Algorithms
    
** Parallel Computing Platform
 - Logical Organization
   - The user's view of the machine as it is being preseent via its system
     software
 - Physical Organization
   - The actual hardware architecture
 - Physical architecture is to a large extent independent of the logical
   architecture

** Logical Organization Elements
- Control Mechanism
  - SISD/SIMD/MIMID/MISD
    - Single/Multiple Instruction Stream & Single/Multiple Data sream
  - SPMD: single program multiple data

#+DOWNLOADED: screenshot @ 2021-07-21 19:04:34
[[file:images/Lecture_1/2021-07-21_19-04-34_screenshot.png]]

** Logical Organization Elements
- Communication Model
  - Shared-address space
  - Message passing
  - UMA/NUMA/ccNUMA
- These are the ways that our processors are communicating (how they are sharing
  memory)
  #+DOWNLOADED: screenshot @ 2021-07-21 19:06:09
  [[file:images/Lecture_1/2021-07-21_19-06-09_screenshot.png]]
- *A*: where all of the processors are sharing an address space
- *B*: where all of the processors have their own local address space and are
  also sharing an address space for all processors
- *C*: where all processors have their own address space and nothing else,
  communication is from local address space to local address space only

** Physical Organization
- Ideal parallel computer architecture is PRAM (parallel random access machine)
- PRAM models:
  - EREW/ERCW/CREW/CRCW
    - Exclusive/Concurrent Read or and write
    - Basically this is all of the read locks and write locks stuff that you
      have covered from SQL, where write locks and read locks don't coexist, but
      multiple read locks can
  - Concurrent writes are resolved via
    - Common/arbitrary/priority/sum
** Physical Organization
- Interconnection Networks (ICN)
  - Provide processor-to-processor and processor-to-memory connections
  - Networks are classified as the following
*** Static
- Consistent of a number of point to point links
  - direct network
- Historically used to link processor to processor
  - Distributed memory system
*** Dynamic
- The network consisted of switching elements that the various processors attach
  to
  - Indirect network
- Historically used to link processors to memory
  - shared memory systems
** Static and Dynamic ICNs

#+DOWNLOADED: screenshot @ 2021-07-21 19:14:24
[[file:images/Lecture_1/2021-07-21_19-14-24_screenshot.png]]

** Evaluation Metrics for ICNs
- Diameter
  - The maximum distance between any two nodes (smaller the better)
- Connectivity
  - The minimum number of arcs that must be removed to break it into two
    disconnected networks (larger the better) (measures the multiplicity of
    paths)
- Bisection width
  - The minimum number of arcs that must be removed to partition the network into
    two equal halves (larger the better)
- Bisection bandwidth
  - Applies to networks with weighted arcs: weights correspond to the link width
    (how much data it can transfer)
  - The minimum volume of communication allowed between any two halves of a
    network (larger the better)
- Cost
  - The number of links in the network (smaller is better)
- Symmetry

#+DOWNLOADED: screenshot @ 2021-07-21 19:19:16
[[file:images/Lecture_1/2021-07-21_19-19-16_screenshot.png]]

** Network Typologies
- Bus based networks
  - Shared medium
  - information is being broadcasted
  - Evaluation
    - Diameter: O(1)
    - Connectivity: O(1)
    - Bisection width: O(1)
    - Cost: O(p)


#+DOWNLOADED: screenshot @ 2021-07-21 19:21:03
[[file:images/Lecture_1/2021-07-21_19-21-03_screenshot.png]]

- Crossbar Networks
  - Switch-based network
  - Supports simultaneous connections
  - Evaluation:
    - Diameter: O(1)
    - Connectivity: O(1)
    - Bisection width: O(p), you can split it in half and still have half the
      network communicate 
    - Cost: O(p^2)

#+DOWNLOADED: screenshot @ 2021-07-22 13:57:16
[[file:images/Lecture_1/2021-07-22_13-57-16_screenshot.png]]
- Multistage Interconnection Networks

#+DOWNLOADED: screenshot @ 2021-07-22 13:57:38
[[file:images/Lecture_1/2021-07-22_13-57-38_screenshot.png]]
- You have to send through multiple stages in order for processors to
  communicate, the communication time is delayed
- The cost is much lower

- Multistage Switch Architecture

#+DOWNLOADED: screenshot @ 2021-07-22 13:59:30
[[file:images/Lecture_1/2021-07-22_13-59-30_screenshot.png]]
- Far less wires, but your communication from address to address is constrained
  by ==log(n)==
- Connecting the Various Stages

#+DOWNLOADED: screenshot @ 2021-07-22 13:59:45
[[file:images/Lecture_1/2021-07-22_13-59-45_screenshot.png]]

- "The perfect shuffle"
** Blocking in a Multistage Switch
- Routing is done by comparing the bit-level representation of source and
  destination addresses
- match goes via pass-through
- Mismatch goes via cross-over

#+DOWNLOADED: screenshot @ 2021-07-22 14:08:16
[[file:images/Lecture_1/2021-07-22_14-08-16_screenshot.png]]

#+DOWNLOADED: screenshot @ 2021-07-22 15:16:44
[[file:images/Lecture_1/2021-07-22_15-16-44_screenshot.png]]
- a) is good if there are no master/slaves
- b) is good for master/slave, there is no need for any of the slaves to
  communicate

* Lecture 2
** Hypercubes
- Look at hamming distance for hypercubes
** Trees
 - If you have two neighbouring processing nodes then you don't have to travel
   very far
** Summary
- You can tell that a completely connected netowrk is nice but cost prohibitive
** Hypercubes revisted
- These can be generated using Cayley Graphs
** Broadcast (telephone communication)
- Broadcast network, you call your friend and they call their friend, every step
  the number of nodes who know about the information doubles
- Soonest everyone can be informed is thus in log(n) steps (n is the number of nodes)
- Broadcast vs gossip
  - gossip is everyone has information while in broadcast there is one souce of
    information
** Physical Organization
- Cache Coherence is when there is a clash in memory because it's stored in two
  different bits of memory that is different from the main global memory
- Ensure that a local cache is coherent with the value that is in the main
  memory
  - Invalidate and update in order to do this
** Topology Embieddings
- You would use some processors in this system in order to create this mapping
- We want a small dilation????
- Meshes map easily onto hypercubes and that's why they are famous
* Misc
- OpenMP second assignment
** SIMD
- Single instruction multiple data stream
- the same instruction is execute synchronously by all processing units
** MIMD
- Each processing element is capable of executing a different program
  independent of the other processing elements
- SIMD computers require less hardware the MIMD computers because they have only
  one global control unit. Furthermore, SIMD computers require less memory
  because only one copy of the program needs to be stored. In contracts, MIMD
  computers store the program and operating system at each processor
** Communication Model of Parallel Platforms
** Parallel Programs
*** Task, Data and Synchronisation
 - Task parallelism: Where you partition tasks carried out in solving the problem
   among the cores and each core carries out more or less similar operations on
   its part of the data
   - Where each marker only marks a single question out of all the questions for
     the papers, cores in this case are carrying out different operations for
     each core
 - Data parallelism: Where you have an amount of data and then you split that
   data amongst the cores and they do the whole workload for that data
   - Where each marker marks whole papers but the stack of papers is split
     between all of the markers, everyone in this context is executing roughly
     the same operations
 - The last type is synchronisation where there must be sync point in order for
   the algorithms to be working together (because each core works at its own pace), therefore if the master core is making data available first then the other cores can't just race off and start computing before the master core has even put up the data, a sync point must be used
*** Types of Memory
 - Shared and distributed, where shared each core can share memory while in the
   distributed setting you have to assume that all memory is private to each core
   (or to each cluster of cores) (shared memory within a multi CPU environment)


 #+DOWNLOADED: screenshot @ 2021-07-20 18:38:25
 [[file:images/Parallel_Programs/2021-07-20_18-38-25_screenshot.png]]

** Parallel Hardware and Parallel Software
 - Memory is used to store both program and data instructions
 - Program instructions are coded data which tell the computer to do something
 - Data is simply information to be used by the program
 - A central processing unit (CPU) gets instructions and/or data from memory,
   decodes the instructions and then *sequentially* performs them

 #+DOWNLOADED: screenshot @ 2021-07-20 19:26:35
 [[file:images/Parallel_Hardware_and_Parallel_Software/2021-07-20_19-26-35_screenshot.png]]

*** Cache mappings
 - *fully associative cache*: is one in which a new line can be placed at any
   location in the cache
 - *direct mapped*: in which each cache line has a unique location in the cache
   to which it will be assigned
 - intermediate solutions are called n-way set associative

** Instruction-level Parallelism
 - An attempt to improve processor performance by having multiple processor
   components (*functional units*) simultaneously executing instructions. There
   are two types, *pipelining* and *multiple issue*
*** Pipelining
 - Divide the machinery for the algorithm into different logical blocks, while
   you are computing the last stage of the algorithm for data x, you can already
   be phasing in data y at the start of the block, this means that one piece of
   computation doesn't have to wait until the other is fully done. not k stage ->
   k fold improvement
** Misc
 - *Write back scheme*: where you write to a piece of memory and put a bit on it
   to indicate that it is dirty, then when it is evicted from memory the bit is
   then checked and if it's a dirty address then you write it back to disk so
   that it can be updated
  
