* Lecture 1
- End goal: achieve speedup of k fold when you have k processors, in the real
  world this doesn't happen but we want to be as close to this as possible, this
  is the upperbound limit
** Elements of a Parallel Computer
 - Hardware
   - Multiple processes
   - Multiple memories
   - Interconnection network (ICN)
 - System Software
   - Parallel operating system
   - Programming constructs to express/orchestrate concurrency
 - Application Software
   - Parallel Algorithms
    
** Parallel Computing Platform
 - Logical Organization
   - The user's view of the machine as it is being preseent via its system
     software
 - Physical Organization
   - The actual hardware architecture
 - Physical architecture is to a large extent independent of the logical
   architecture

** Logical Organization Elements
- Control Mechanism
  - SISD/SIMD/MIMID/MISD
    - Single/Multiple Instruction Stream & Single/Multiple Data sream
  - SPMD: single program multiple data

#+DOWNLOADED: screenshot @ 2021-07-21 19:04:34
[[file:images/Lecture_1/2021-07-21_19-04-34_screenshot.png]]

** Logical Organization Elements
- Communication Model
  - Shared-address space
  - Message passing
  - UMA/NUMA/ccNUMA
- These are the ways that our processors are communicating (how they are sharing
  memory)
  #+DOWNLOADED: screenshot @ 2021-07-21 19:06:09
  [[file:images/Lecture_1/2021-07-21_19-06-09_screenshot.png]]
- *A*: where all of the processors are sharing an address space
- *B*: where all of the processors have their own local address space and are
  also sharing an address space for all processors
- *C*: where all processors have their own address space and nothing else,
  communication is from local address space to local address space only

** Physical Organization
- Ideal parallel computer architecture is PRAM (parallel random access machine)
- PRAM models:
  - EREW/ERCW/CREW/CRCW
    - Exclusive/Concurrent Read or and write
    - Basically this is all of the read locks and write locks stuff that you
      have covered from SQL, where write locks and read locks don't coexist, but
      multiple read locks can
  - Concurrent writes are resolved via
    - Common/arbitrary/priority/sum
** Physical Organization
- Interconnection Networks (ICN)
  - Provide processor-to-processor and processor-to-memory connections
  - Networks are classified as the following
*** Static
- Consistent of a number of point to point links
  - direct network
- Historically used to link processor to processor
  - Distributed memory system
*** Dynamic
- The network consisted of switching elements that the various processors attach
  to
  - Indirect network
- Historically used to link processors to memory
  - shared memory systems
** Static and Dynamic ICNs

#+DOWNLOADED: screenshot @ 2021-07-21 19:14:24
[[file:images/Lecture_1/2021-07-21_19-14-24_screenshot.png]]

** Evaluation Metrics for ICNs
- Diameter
  - The maximum distance between any two nodes (smaller the better)
- Connectivity
  - The minimum number of arcs that must be removed to break it into two
    disconnected networks (larger the better) (measures the multiplicity of
    paths)
- Bisection width
  - The minimum number of arcs that must be removed to partition the network into
    two equal halves (larger the better)
- Bisection bandwidth
  - Applies to networks with weighted arcs: weights correspond to the link width
    (how much data it can transfer)
  - The minimum volume of communication allowed between any two halves of a
    network (larger the better)
- Cost
  - The number of links in the network (smaller is better)
- Symmetry

#+DOWNLOADED: screenshot @ 2021-07-21 19:19:16
[[file:images/Lecture_1/2021-07-21_19-19-16_screenshot.png]]

** Network Typologies
- Bus based networks
  - Shared medium
  - information is being broadcasted
  - Evaluation
    - Diameter: O(1)
    - Connectivity: O(1)
    - Bisection width: O(1)
    - Cost: O(p)


#+DOWNLOADED: screenshot @ 2021-07-21 19:21:03
[[file:images/Lecture_1/2021-07-21_19-21-03_screenshot.png]]

- Crossbar Networks
  - Switch-based network
  - Supports simultaneous connections
  - Evaluation:
    - Diameter: O(1)
    - Connectivity: O(1)
    - Bisection width: O(p), you can split it in half and still have half the
      network communicate 
    - Cost: O(p^2)

#+DOWNLOADED: screenshot @ 2021-07-22 13:57:16
[[file:images/Lecture_1/2021-07-22_13-57-16_screenshot.png]]
- Multistage Interconnection Networks

#+DOWNLOADED: screenshot @ 2021-07-22 13:57:38
[[file:images/Lecture_1/2021-07-22_13-57-38_screenshot.png]]
- You have to send through multiple stages in order for processors to
  communicate, the communication time is delayed
- The cost is much lower

- Multistage Switch Architecture

#+DOWNLOADED: screenshot @ 2021-07-22 13:59:30
[[file:images/Lecture_1/2021-07-22_13-59-30_screenshot.png]]
- Far less wires, but your communication from address to address is constrained
  by ==log(n)==
- Connecting the Various Stages

#+DOWNLOADED: screenshot @ 2021-07-22 13:59:45
[[file:images/Lecture_1/2021-07-22_13-59-45_screenshot.png]]

- "The perfect shuffle"
** Blocking in a Multistage Switch
- Routing is done by comparing the bit-level representation of source and
  destination addresses
- match goes via pass-through
- Mismatch goes via cross-over

#+DOWNLOADED: screenshot @ 2021-07-22 14:08:16
[[file:images/Lecture_1/2021-07-22_14-08-16_screenshot.png]]

#+DOWNLOADED: screenshot @ 2021-07-22 15:16:44
[[file:images/Lecture_1/2021-07-22_15-16-44_screenshot.png]]
- a) is good if there are no master/slaves
- b) is good for master/slave, there is no need for any of the slaves to
  communicate

* Lecture 2
** Hypercubes
- Look at hamming distance for hypercubes
** Trees
 - If you have two neighbouring processing nodes then you don't have to travel
   very far
** Summary
- You can tell that a completely connected netowrk is nice but cost prohibitive
** Hypercubes revisted
- These can be generated using Cayley Graphs
** Broadcast (telephone communication)
- Broadcast network, you call your friend and they call their friend, every step
  the number of nodes who know about the information doubles
- Soonest everyone can be informed is thus in log(n) steps (n is the number of nodes)
- Broadcast vs gossip
  - gossip is everyone has information while in broadcast there is one souce of
    information
** Physical Organization
- Cache Coherence is when there is a clash in memory because it's stored in two
  different bits of memory that is different from the main global memory
- Ensure that a local cache is coherent with the value that is in the main
  memory
  - Invalidate and update in order to do this
** Topology Embieddings
- You would use some processors in this system in order to create this mapping
- We want a small dilation????
- Meshes map easily onto hypercubes and that's why they are famous
* Lecture 3
Now that we have covered some mappings and topologies we are going to go through
some algs (sequential)
** Dense Matrix-Vector Multiplication
- ==O(n^2)==, two nested for loops
- hopefully when we are parallelising this then you're going to get a better
  order than n^2
** Dense Matrix-Matrix Multiplication
- Two matrices multiplied which is ==O(n^3)==, remember you can makes this
  better by using divide and conquer
** Sparse Matrix-Vector Multiplication
- Hopefully we can do better than n^2 when we have less than n^2 entries in the
  matrix or vector, in the diagram the black dots are non-zero, obvious if
  something is zero we can skip that multiplication because it's obviously going
  to be zero when we are done with it
** Floyd's All-Pairs Shortest Path
- The shortest path between all pairs of nodes the in the graph. It's a O(n^3),
  you're basically bruting for a shortest path
** Quicksort
- Using element q (picked at random) as a pivot, where everything to the left is
  less than q and everything to the right is greater than q. You then apply this
  recursively to the subparts
- Although this algorithm in the lides might be a bit different, don't be too
  surprised about this
** Minimum Finding
Nothing to note, he talked about FP being able to reduce this though
** 15-Puzzle Problem
- Final goal state is a sorted magic square
- You should look this up, i havne't seen this before
- You want to find the shortest solution (in number of moves) or just a
 solution
- You're just shuffling things around until you get an ordering
** Parallel Algorithm vs Parallel Formulation
- Parallel Formulation
  - Refers to a parallelization of a serial algorithm, you're using the serial
    algorithm and then you're parallelising it
- Parallel Algorithm
  - May represent an entirely different algorithm than that one used serially
- We primarily focus on "Parallel Formulations"
  - Our goal today is to primarily discuss how to develop such parallel
    formulations
  - Of course there will always be examples of "parallel algorithms" that were
    not derived from serial algorithms
** Elements of a Parallel Algorithm/Formulation
- Pieces of work that can be done concurrently
  - tasks
- Mapping of the tasks onto multiple processors
  - Processes vs Processors and how to balance the two
- Distribution of input/output ^ intermediate data across the different
  processors
- Management the access of shared data
  - Either input or intermediate
- Synchronization of the processors at various points of the parallel execution
- The best outcome is k processes decrease the runtime by k-fold
** Finding Concurrent Pieces of Work
- Decomposition
  - The process of dividing the compution into smaller pieces of work, ie *tasks*
    - Note that if you can identify this then you basically have done yourself a
      huge favour because this is the hard part of this, usually when you figure
      out how to do this step then you will have a good idea on how to do the
      rest
- Tasks are programmer dfined and are considered to be indivisible (they are the
  minimum unit), also called the granularity of the  task
** Example: Query Processing
- The first (left) is better here because the subtasks are not as dependent as
  the one on the right, precedence directed graph
** Task-Dependency Graph (cont)
- Key concepts derived from the task-dependency graph
  - Degree of Concurrency
    - The number of tasks that can be concurrently executed
      - We usually care about the average degree of concurrency
  - Critical Path
    - The longest vertex-weighted path in the graph
      - The weights represent task size, whatever is your longest critical task
        is going to bound your runtime (weakest link mindset), you are trying to
        minimize this
      - Even though they have the same critical path, the first one is
        preferable because it has better concurrency
  - Tasks granularity affects both of the above characteristics
** Task-Interaction Graph
- Captures the pattern of interaction between tasks
  - This graph usually contains the task-dependency graph as a subgraph
    - I:e there may be interacgtions between tasks even if there are no
      dependencies
      - These interactions usually occur due to accesses on shared data

#+DOWNLOADED: screenshot @ 2021-07-26 15:53:20
[[file:images/Lecture_3/2021-07-26_15-53-20_screenshot.png]]
- You are inserting an edge if there is some interaction between processors in
  order to complete or compose tasks together

** Tasks Dependency/Interactoin Graphs
- These graphs are important in developing effectively mapping the tasks onto
  the different processors
  - Maximuze concurrency and minimuze overheads

#+DOWNLOADED: screenshot @ 2021-07-26 15:55:45
[[file:images/Lecture_3/2021-07-26_15-55-45_screenshot.png]]

* Misc
- OpenMP second assignment
** SIMD
- Single instruction multiple data stream
- the same instruction is execute synchronously by all processing units
** MIMD
- Each processing element is capable of executing a different program
  independent of the other processing elements
- SIMD computers require less hardware the MIMD computers because they have only
  one global control unit. Furthermore, SIMD computers require less memory
  because only one copy of the program needs to be stored. In contracts, MIMD
  computers store the program and operating system at each processor
** Communication Model of Parallel Platforms
** Parallel Programs
*** Task, Data and Synchronisation
 - Task parallelism: Where you partition tasks carried out in solving the problem
   among the cores and each core carries out more or less similar operations on
   its part of the data
   - Where each marker only marks a single question out of all the questions for
     the papers, cores in this case are carrying out different operations for
     each core
 - Data parallelism: Where you have an amount of data and then you split that
   data amongst the cores and they do the whole workload for that data
   - Where each marker marks whole papers but the stack of papers is split
     between all of the markers, everyone in this context is executing roughly
     the same operations
 - The last type is synchronisation where there must be sync point in order for
   the algorithms to be working together (because each core works at its own pace), therefore if the master core is making data available first then the other cores can't just race off and start computing before the master core has even put up the data, a sync point must be used
*** Types of Memory
 - Shared and distributed, where shared each core can share memory while in the
   distributed setting you have to assume that all memory is private to each core
   (or to each cluster of cores) (shared memory within a multi CPU environment)


 #+DOWNLOADED: screenshot @ 2021-07-20 18:38:25
 [[file:images/Parallel_Programs/2021-07-20_18-38-25_screenshot.png]]

** Parallel Hardware and Parallel Software
 - Memory is used to store both program and data instructions
 - Program instructions are coded data which tell the computer to do something
 - Data is simply information to be used by the program
 - A central processing unit (CPU) gets instructions and/or data from memory,
   decodes the instructions and then *sequentially* performs them

 #+DOWNLOADED: screenshot @ 2021-07-20 19:26:35
 [[file:images/Parallel_Hardware_and_Parallel_Software/2021-07-20_19-26-35_screenshot.png]]

*** Cache mappings
 - *fully associative cache*: is one in which a new line can be placed at any
   location in the cache
 - *direct mapped*: in which each cache line has a unique location in the cache
   to which it will be assigned
 - intermediate solutions are called n-way set associative

** Instruction-level Parallelism
 - An attempt to improve processor performance by having multiple processor
   components (*functional units*) simultaneously executing instructions. There
   are two types, *pipelining* and *multiple issue*
*** Pipelining
 - Divide the machinery for the algorithm into different logical blocks, while
   you are computing the last stage of the algorithm for data x, you can already
   be phasing in data y at the start of the block, this means that one piece of
   computation doesn't have to wait until the other is fully done. not k stage ->
   k fold improvement
** Misc
 - *Write back scheme*: where you write to a piece of memory and put a bit on it
   to indicate that it is dirty, then when it is evicted from memory the bit is
   then checked and if it's a dirty address then you write it back to disk so
   that it can be updated
  
